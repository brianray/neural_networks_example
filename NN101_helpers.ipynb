{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import olivetti_faces as facedata\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import image\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.decomposition import pca\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from time import time\n",
    "import numpy as np\n",
    "fd = facedata.fetch_olivetti_faces()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_face_row(face_n, show=np.ones(10)):\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(1, 10, wspace=0.0)\n",
    "    ax = [plt.subplot(gs[i]) for i in range(10)]\n",
    "    gs.update(hspace=0)\n",
    "    print \"face #%s\" % face_n\n",
    "    for i in range(face_n*10,face_n*10+10):\n",
    "        if show[i-face_n*10]==1:\n",
    "            ax[i-face_n*10].imshow(fd.images[i], cmap='gist_gray')\n",
    "            ax[i-face_n*10].axis('off')\n",
    "        else:\n",
    "            ax[i-face_n*10].imshow(np.ones((64,64)), cmap='gist_gray')\n",
    "            ax[i-face_n*10].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "housing = load_boston()\n",
    "#help(housing)\n",
    "#print housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get individuals\n",
    "individuals = fd.target\n",
    "itraining = np.arange(0,fd.target.shape[0]) % 10 == 0\n",
    "\n",
    "#get_glasses\n",
    "has_glasses = np.zeros(len(fd.images))\n",
    "def fill_ones(arr, face_n, ind=range(10)):\n",
    "    for i in ind:\n",
    "        arr[face_n*10+i] = 1\n",
    "    return arr\n",
    "has_glasses = fill_ones(has_glasses, 1)\n",
    "has_glasses = fill_ones(has_glasses, 3, [0,1,2,7,8])\n",
    "has_glasses = fill_ones(has_glasses, 5)\n",
    "has_glasses = fill_ones(has_glasses, 6, [3,4,9])\n",
    "has_glasses = fill_ones(has_glasses, 12, [0,1,4,5,6,7,8,9])\n",
    "has_glasses = fill_ones(has_glasses, 13)\n",
    "has_glasses = fill_ones(has_glasses, 16,[0,1,4,5,6,7,8,9])\n",
    "has_glasses = fill_ones(has_glasses, 18, [0,1,2,5,9])\n",
    "has_glasses = fill_ones(has_glasses, 19, [0,1,2,4,6,7,8,9])\n",
    "has_glasses = fill_ones(has_glasses, 26)\n",
    "has_glasses = fill_ones(has_glasses, 27)\n",
    "has_glasses = fill_ones(has_glasses, 30)\n",
    "has_glasses = fill_ones(has_glasses, 33)\n",
    "has_glasses = fill_ones(has_glasses, 35, [8,9])\n",
    "has_glasses = fill_ones(has_glasses, 36)\n",
    "\n",
    "gtraining = ~np.in1d(fd.target, np.array([16,18]))\n",
    "\n",
    "has_beard = np.zeros(len(fd.target), dtype=np.int8)\n",
    "has_beard[np.in1d(fd.target, np.array([6,10,13,15,16,24,25,27,36,]))]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten data and setup targets\n",
    "flattened_data = []\n",
    "target_glasses = []\n",
    "for i in range(len(fd.images)):\n",
    "    flattened_data.append(fd.images[i].flatten())\n",
    "    target_glasses.append(has_glasses[i])\n",
    "flattened_data = np.array(flattened_data)\n",
    "target_glasses = np.array(target_glasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_neurons(nn, layer = 0):\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    if np.sqrt(nn.coefs_[layer].shape[0]) % 1 == 0:\n",
    "        shape = (int(np.sqrt(nn.coefs_[layer].shape[0])), \n",
    "                 int(np.sqrt(nn.coefs_[layer].shape[0])))\n",
    "    else:\n",
    "        shape = (nn.coefs_[layer].shape[0],1)\n",
    "    gs = gridspec.GridSpec(1, nn.coefs_[layer].shape[1], wspace=0.0)\n",
    "    ax = [plt.subplot(gs[i]) for i in range(nn.coefs_[layer].shape[1])]\n",
    "    for i in range(nncls.coefs_[layer].shape[1]):\n",
    "        neuron = nncls.coefs_[layer][:,i].reshape(shape)\n",
    "        gs.update(hspace=0)\n",
    "        ax[i].imshow(neuron, cmap='gist_gray', interpolation=\"nearest\")\n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_roc_curve(data, target, model, selection):\n",
    "    return roc_curve(target[selection], model.predict_proba(data[selection])[:,0], drop_intermediate=False)\n",
    "\n",
    "def plot_roc(data, target, model1, model2, selection):\n",
    "    tpr1, fpr1, thh1 = return_roc_curve(data, target, model1, selection)\n",
    "    tpr2, fpr2, thh2 = return_roc_curve(data, target, model2, selection)\n",
    "    p = plt.plot(fpr1, tpr1, 'blue', fpr2, tpr2, 'red', np.array([0,1]),np.array([0,1]), \"black\", zorder=10)\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    print \"AUC model 1:\", auc(fpr1, tpr1)\n",
    "    print \"AUC model 2:\", auc(fpr2, tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learning_curve(model, data, target, test_set, step=20, rs=1000):\n",
    "    in_samp_accs = []\n",
    "    out_samp_accs = []\n",
    "    benchmarks = []\n",
    "    np.random.seed(rs)\n",
    "    for sample_size in range(19, np.sum(~test_set), step):\n",
    "        selection = np.random.choice(np.arange(0,fd.target.shape[0])[np.arange(0,fd.target.shape[0])], sample_size)\n",
    "        data[selection,:]\n",
    "        benchmark = time()\n",
    "        m = model.fit(data[selection,:], has_glasses[selection])\n",
    "        benchmark = (time() - benchmark) # time in seconds\n",
    "        in_samp_acc =  m.score(data[selection,:], has_glasses[selection])\n",
    "        out_samp_acc = m.score(data[test_set,:], has_glasses[test_set])\n",
    "        print \"training round: %s sample size, in sample: %s, out sample: %s, benchmark: %s\" % (\n",
    "            has_glasses[selection].shape,\n",
    "            in_samp_acc,\n",
    "            out_samp_acc,\n",
    "            benchmark\n",
    "        )\n",
    "        in_samp_accs.append(in_samp_acc)\n",
    "        out_samp_accs.append(out_samp_acc)\n",
    "        benchmarks.append(benchmark)\n",
    "    np.random.seed(None)\n",
    "    return (\n",
    "        range(19, np.sum(~test_set), step),\n",
    "        in_samp_accs,\n",
    "        out_samp_accs,\n",
    "        benchmarks\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
